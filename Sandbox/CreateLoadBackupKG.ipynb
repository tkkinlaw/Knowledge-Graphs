{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.graph import KnowledgeGraph\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder name\n",
    "output_folder = r\"C:\\backups\\myknowledgegraph_backup\"\n",
    "\n",
    "# Connecting to the GIS\n",
    "gisPortalUrl = \"https://adsrv2019.ad.local/portal\"\n",
    "username = \"tkinlaw_ent\"\n",
    "password = \"Esri.4.GIS\"\n",
    "url = r\"https://adsrv2019.ad.local/server/rest/services/Hosted/HealthcareRecords/KnowledgeGraphServer\" # provide the serice url for the input KG\n",
    "gis = GIS(gisPortalUrl, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define folder and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output backup json file names\n",
    "dm_ent = \"datamodel_entities.json\"\n",
    "dm_rel = \"datamodel_relationships.json\"\n",
    "all_ent = \"all_entities.json\"\n",
    "all_rel = \"all_relationships.json\"\n",
    "prov_file = \"provenance_entities.json\"  # this will only be used if you want to backup provenance records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create backup files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to portal and knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to knowledge graph service\n",
    "knowledgegraph_backup = KnowledgeGraph(url=url, gis=gis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data model entity types to backup json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of formatted entity types\n",
    "entity_types = []\n",
    "for types in knowledgegraph_backup.datamodel[\"entity_types\"]:\n",
    "    curr_entity_type = {\n",
    "        \"name\": knowledgegraph_backup.datamodel[\"entity_types\"][types][\"name\"],\n",
    "        \"properties\": knowledgegraph_backup.datamodel[\"entity_types\"][types][\"properties\"]\n",
    "        }\n",
    "    entity_types.append(curr_entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write entity types to json file\n",
    "with open(os.path.join(output_folder, dm_ent), \"w\") as f:\n",
    "    json.dump(entity_types, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data model relationship types to backup json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of formatted relationship types\n",
    "relationship_types = []\n",
    "for types in knowledgegraph_backup.datamodel[\"relationship_types\"]:\n",
    "    curr_relationship_type = {\n",
    "        \"name\": knowledgegraph_backup.datamodel[\"relationship_types\"][types][\"name\"],\n",
    "        \"properties\": knowledgegraph_backup.datamodel[\"relationship_types\"][types][\"properties\"]\n",
    "    }\n",
    "    relationship_types.append(curr_relationship_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write relationship types to json file\n",
    "with open(os.path.join(output_folder, dm_rel), \"w\") as f:\n",
    "    json.dump(relationship_types, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write entities to backup json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for all entities in graph\n",
    "original_entities = knowledgegraph_backup.query_streaming(\n",
    "    \"MATCH (n) RETURN distinct n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of formatted entities to add to the graph\n",
    "all_entities_fromquery = []\n",
    "for entity in list(original_entities):\n",
    "    curr_entity = entity[0]\n",
    "    # convert UUID values to a string since json can't store UUIDs\n",
    "    curr_entity[\"_id\"] = str(curr_entity[\"_id\"])\n",
    "    for prop in curr_entity[\"_properties\"]:\n",
    "        if type(curr_entity[\"_properties\"][prop]) == UUID:\n",
    "            curr_entity[\"_properties\"][prop] = str(curr_entity[\"_properties\"][prop])\n",
    "    # delete objectid, the server will handle creating new ones when we load the backup\n",
    "    del curr_entity[\"_properties\"][\n",
    "        \"objectid\"\n",
    "    ]\n",
    "    all_entities_fromquery.append(curr_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write entities list to json file\n",
    "with open(os.path.join(output_folder, all_ent), \"w\") as f:\n",
    "    json.dump(all_entities_fromquery, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write relationships to backup json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for all relationships in graph\n",
    "original_relationships = knowledgegraph_backup.query_streaming(\n",
    "    \"MATCH ()-[rel]->() RETURN distinct rel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of formatted entities to add to the graph\n",
    "all_relationships_fromquery = []\n",
    "for relationship in list(original_relationships):\n",
    "    curr_relationship = relationship[0]\n",
    "    # convert UUID values to a string since json can't store UUIDs\n",
    "    curr_relationship[\"_id\"] = str(curr_relationship[\"_id\"])\n",
    "    curr_relationship[\"_originEntityId\"] = str(curr_relationship[\"_originEntityId\"])\n",
    "    curr_relationship[\"_destinationEntityId\"] = str(\n",
    "        curr_relationship[\"_destinationEntityId\"]\n",
    "    )\n",
    "    for prop in curr_relationship[\"_properties\"]:\n",
    "        if type(curr_relationship[\"_properties\"][prop]) == UUID:\n",
    "            curr_relationship[\"_properties\"][prop] = str(\n",
    "                curr_relationship[\"_properties\"][prop]\n",
    "            )\n",
    "    # delete objectid, the server will handle creating new ones when we load the backup\n",
    "    del curr_relationship[\"_properties\"][\n",
    "        \"objectid\"\n",
    "    ]\n",
    "    all_relationships_fromquery.append(curr_relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write relationships list to json file\n",
    "with open(os.path.join(output_folder, all_rel), \"w\") as f:\n",
    "    json.dump(all_relationships_fromquery, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: Write provenance records to backup json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for all provenance records in the graph\n",
    "provenance_entities = knowledgegraph_backup.query_streaming(\n",
    "    \"MATCH (n:Provenance) RETURN distinct n\", include_provenance=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of formatted provenance records to the graph\n",
    "all_provenance_fromquery = []\n",
    "for entity in list(provenance_entities):\n",
    "    curr_provenance = entity[0]\n",
    "    # convert UUID values to a string since json can't store UUIDs\n",
    "    curr_provenance[\"_id\"] = str(curr_provenance[\"_id\"])\n",
    "    for prop in curr_provenance[\"_properties\"]:\n",
    "        if type(curr_provenance[\"_properties\"][prop]) == UUID:\n",
    "            curr_provenance[\"_properties\"][prop] = str(\n",
    "                curr_provenance[\"_properties\"][prop]\n",
    "            )\n",
    "    # delete objectid, the server will handle creating new ones when we load the backup\n",
    "    del curr_provenance[\"_properties\"][\n",
    "        \"objectid\"\n",
    "    ]\n",
    "    all_provenance_fromquery.append(curr_provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write provenance list to json file\n",
    "with open(os.path.join(output_folder, prov_file), \"w\") as f:\n",
    "    json.dump(all_provenance_fromquery, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load backup files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to portal and create knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a knowledge graph without provenance enabled\n",
    "result = gis.content.create_service(\n",
    "    name=\"myknowledgegraph\",\n",
    "    capabilities=\"Query,Editing,Create,Update,Delete\",\n",
    "    service_type=\"KnowledgeGraph\"\n",
    ")\n",
    "knowledgegraph_load = KnowledgeGraph(result.url, gis=gis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will need to be modified if we work with provenance in the class data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate data model from saved json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data model json files into graph data model\n",
    "with open(os.path.join(output_folder, dm_ent), \"r\") as file:\n",
    "    dm_ents = json.load(file)\n",
    "with open(os.path.join(output_folder, dm_rel), \"r\") as file:\n",
    "    dm_rels = json.load(file)\n",
    "knowledgegraph_load.named_object_type_adds(\n",
    "    entity_types=dm_ents, relationship_types=dm_rels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get original documents names to correctly load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document entity type name\n",
    "doc_type_name = \"Document\"\n",
    "for entity_type in dm_ents:\n",
    "    for prop in entity_type[\"properties\"]:\n",
    "        if entity_type[\"properties\"][prop][\"role\"] == \"esriGraphNamedObjectDocument\":\n",
    "            doc_type_name = entity_type[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document relationship type name\n",
    "doc_rel_type_name = \"HasDocument\"\n",
    "for relationship_type in dm_rels:\n",
    "    for prop in relationship_type[\"properties\"]:\n",
    "        if (\n",
    "            relationship_type[\"properties\"][prop][\"role\"]\n",
    "            == \"esriGraphNamedObjectDocument\"\n",
    "        ):\n",
    "            doc_rel_type_name = relationship_type[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional document entity and relationship type properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any additional document entity type properties\n",
    "origin_document_properties = None\n",
    "for entity_type in dm_ents:\n",
    "    if entity_type[\"name\"] == doc_type_name:\n",
    "        origin_document_properties = entity_type[\"properties\"]\n",
    "prop_list = []\n",
    "for prop in origin_document_properties:\n",
    "    prop_list.append(origin_document_properties[prop])\n",
    "knowledgegraph_load.graph_property_adds(\n",
    "    type_name=\"Document\", graph_properties=prop_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any additional document relationship type properties\n",
    "for relationship_type in dm_rels:\n",
    "    if relationship_type[\"name\"] == doc_rel_type_name:\n",
    "        origin_document_rel_properties = relationship_type[\"properties\"]\n",
    "prop_list = []\n",
    "for prop in origin_document_rel_properties:\n",
    "    prop_list.append(origin_document_rel_properties[prop])\n",
    "knowledgegraph_load.graph_property_adds(\n",
    "    type_name=\"HasDocument\", graph_properties=prop_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of date properties from the data model json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_properties = []\n",
    "# add date property names for entity types\n",
    "for types in dm_ents:\n",
    "    for prop in types[\"properties\"]:\n",
    "        if types[\"properties\"][prop][\"fieldType\"] == \"esriFieldTypeDate\":\n",
    "            date_properties.append(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date property names for relationship types\n",
    "for types in dm_rels:\n",
    "    for prop in types[\"properties\"]:\n",
    "        if types[\"properties\"][prop][\"fieldType\"] == \"esriFieldTypeDate\":\n",
    "            date_properties.append(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all entities to the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entities json file\n",
    "with open(os.path.join(output_folder, all_ent), \"r\") as file:\n",
    "    original_entities = json.load(file)\n",
    "batch = []\n",
    "for curr_entity in original_entities:\n",
    "    # if a batch reaches 20k records, apply that batch of edits to the knowledge graph\n",
    "    if len(batch) > 20000:\n",
    "        result = knowledgegraph_load.apply_edits(adds=batch)\n",
    "        batch = []\n",
    "        # print error if one occurs during edit operation\n",
    "        try:\n",
    "            print(result[\"error\"])\n",
    "        except:\n",
    "            print(\"No error adding entities\")\n",
    "    # in case original document type name is different, change name to Document\n",
    "    if curr_entity[\"_typeName\"] == doc_type_name:\n",
    "        curr_entity[\"_typeName\"] = \"Document\"\n",
    "    # format UUID and date properties\n",
    "    for prop in curr_entity[\"_properties\"]:\n",
    "        if prop in date_properties:\n",
    "            try:\n",
    "                curr_entity[\"_properties\"][prop] = datetime.fromtimestamp(\n",
    "                    int(curr_entity[\"_properties\"][prop] / 1000)\n",
    "                )\n",
    "            except:\n",
    "                curr_entity[\"_properties\"][prop] = None\n",
    "        try:\n",
    "            curr_entity[\"_properties\"][prop] = UUID(curr_entity[\"_properties\"][prop])\n",
    "        except:\n",
    "            continue\n",
    "    # format id UUID\n",
    "    curr_entity[\"_id\"] = UUID(curr_entity[\"_id\"])\n",
    "    batch.append(curr_entity)\n",
    "# apply final batch of edits to the knowledge graph\n",
    "result = knowledgegraph_load.apply_edits(adds=batch)\n",
    "# print error if one occurs during edit operation\n",
    "try:\n",
    "    print(result[\"error\"])\n",
    "except:\n",
    "    print(\"No error adding entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all relationships to the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load relationships json file\n",
    "with open(os.path.join(output_folder, all_rel), \"r\") as file:\n",
    "    original_rels = json.load(file)\n",
    "batch = []\n",
    "for curr_relationship in original_rels:\n",
    "    # if a batch reaches 20k records, apply that batch of edits to the knowledge graph\n",
    "    if len(batch) > 20000:\n",
    "        result = knowledgegraph_load.apply_edits(adds=batch)\n",
    "        batch = []\n",
    "        # print error if one occurs during edit operation\n",
    "        try:\n",
    "            print(result[\"error\"])\n",
    "        except:\n",
    "            print(\"No error adding relationships\")\n",
    "    # in case original document type name is different, change name to HasDocument\n",
    "    if curr_relationship[\"_typeName\"] == doc_rel_type_name:\n",
    "        curr_relationship[\"_typeName\"] = \"HasDocument\"\n",
    "    # format UUID and date properties\n",
    "    for prop in curr_relationship[\"_properties\"]:\n",
    "        if prop in date_properties:\n",
    "            try:\n",
    "                curr_relationship[\"_properties\"][prop] = datetime.fromtimestamp(\n",
    "                    int(curr_relationship[\"_properties\"][prop] / 1000)\n",
    "                )\n",
    "            except:\n",
    "                curr_relationship[\"_properties\"][prop] = None\n",
    "        try:\n",
    "            curr_relationship[\"_properties\"][prop] = UUID(\n",
    "                curr_relationship[\"_properties\"][prop]\n",
    "            )\n",
    "        except:\n",
    "            continue\n",
    "    # format other relationship specific UUIDs\n",
    "    curr_relationship[\"_id\"] = UUID(curr_relationship[\"_id\"])\n",
    "    curr_relationship[\"_originEntityId\"] = UUID(curr_relationship[\"_originEntityId\"])\n",
    "    curr_relationship[\"_destinationEntityId\"] = UUID(\n",
    "        curr_relationship[\"_destinationEntityId\"]\n",
    "    )\n",
    "    batch.append(curr_relationship)\n",
    "# apply final batch of edits to the knowledge graph\n",
    "result = knowledgegraph_load.apply_edits(adds=batch)\n",
    "# print error if one occurs during edit operation\n",
    "try:\n",
    "    print(result[\"error\"])\n",
    "except:\n",
    "    print(\"No error adding relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add search indexes to all text properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dm = knowledgegraph_load.datamodel\n",
    "# add search indexes for all entity text properties\n",
    "for entity_type in load_dm[\"entity_types\"]:\n",
    "    prop_list = []\n",
    "    for prop in load_dm[\"entity_types\"][entity_type][\"properties\"]:\n",
    "        if (\n",
    "            load_dm[\"entity_types\"][entity_type][\"properties\"][prop][\"fieldType\"]\n",
    "            == \"esriFieldTypeString\"\n",
    "        ):\n",
    "            prop_list.append(prop)\n",
    "    knowledgegraph_load.update_search_index(\n",
    "        adds={entity_type: {\"property_names\": prop_list}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add search indexes for all relationship text properties\n",
    "for entity_type in load_dm[\"relationship_types\"]:\n",
    "    prop_list = []\n",
    "    for prop in load_dm[\"relationship_types\"][entity_type][\"properties\"]:\n",
    "        if (\n",
    "            load_dm[\"relationship_types\"][entity_type][\"properties\"][prop][\"fieldType\"]\n",
    "            == \"esriFieldTypeString\"\n",
    "        ):\n",
    "            prop_list.append(prop)\n",
    "    knowledgegraph_load.update_search_index(\n",
    "        adds={entity_type: {\"property_names\": prop_list}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL: Add provenance records to the knowledge graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load provenance records json file\n",
    "with open(os.path.join(output_folder, prov_file), \"r\") as file:\n",
    "    prov_entities = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add all provenance records\n",
    "for curr_prov in prov_entities:\n",
    "    # format UUID properties\n",
    "    for prop in curr_prov[\"_properties\"]:\n",
    "        try:\n",
    "            curr_prov[\"_properties\"][prop] = UUID(curr_prov[\"_properties\"][prop])\n",
    "        except:\n",
    "            continue\n",
    "    # format id as UUID\n",
    "    curr_prov[\"_id\"] = UUID(curr_prov[\"_id\"])\n",
    "    # add provenance record\n",
    "    knowledgegraph_load.apply_edits(adds=[curr_prov])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
